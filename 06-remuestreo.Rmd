# Intervalos de confianza y remuestreo

En la sección anterior, vimos el concepto de distribución de muestreo
de una estadística que queremos utilizar para estimar un valor poblacional, y
vimos que con esta distribución podíamos evaluar qué tan preciso es nuestro
estimador evaluando qué tan concentrada está esta distribución alrededor
del valor poblacion que queremos estimar.

Sin embargo, en los ejemplos que vimos la población era conocida: ya sea
que tuviéramos toda la población finita disponible (como el ejemplo de las casas),
o donde la población estaba definida por un modelo teórico de probabilidad
(como los ejemplos de las distribuciones uniforme o exponencial).

Ahora vemos qué hacer en el caso que realmente nos interesa: solo tenemos
una muestra disponible, y la población es desconocida. Todo lo que tenemos
es una muestra y una estimación basada en la muestra, y requerimos estimar
la distribución de muestreo de la estadística de interés. El enfoque
que presentaremos aquí es uno de los más flexibles y poderosos que están
disponible para este problema: el método **bootstrap** o de **remuestreo**.

En primer lugar explicamos el concepto de intervalo de confianza, que es una
manera resumida de evaluar la precisión de nuestras estimaciones.


## Ejemplo introductorio {-}

Regresamos a nuestro ejemplo anterior donde muestreamos 3 grupos, y nos preguntábamos
acerca de la diferencia de sus medianas. En lugar de hacer pruebas de permutaciones 
(ya sea pruebas gráficas o alguna prueba de permutaciones para media o mediana, por ejemplo),
podríamos considerar qué tan precisa es cada una de nuestras estimaciones
para las medianas de los grupos.

Nuestros resultados podríamos presentarlos como sigue:

```{r, echo = FALSE, message = FALSE}
set.seed(8)
pob_tab <- tibble(id = 1:2000, x = rgamma(2000, 4, 1), 
    grupo = sample(c("a","b", "c"), 2000, prob = c(4,2,1), replace = T))
muestra_tab <- pob_tab %>% sample_n(125)
g_1 <- ggplot(muestra_tab, aes(x = grupo, y = x)) + geom_boxplot(outlier.alpha = 0) +
    geom_jitter(alpha = 0.3) + 
      labs(subtitle = "Muestra \n") + ylim(c(0,14))
## Hacemos bootstrap
fun_boot <- function(datos){
    datos %>% group_by(grupo) %>% sample_n(n(), replace = T)
}
reps_boot <- map(1:2000, function(i){
    medianas <- muestra_tab %>% 
        fun_boot %>% 
        group_by(grupo) %>% 
        summarise(mediana = median(x))
    medianas %>% mutate(rep = i)
}) %>% bind_rows
resumen_boot <- reps_boot %>% group_by(grupo) %>% 
    summarise(ymin = quantile(mediana, 0.025), ymax = quantile(mediana, 0.975)) %>% 
    left_join(muestra_tab %>% group_by(grupo) %>% summarise(mediana = median(x)))
g_2 <- ggplot(resumen_boot, aes(x = grupo, y = mediana, ymin = ymin, ymax = ymax)) +
    geom_linerange() +
    geom_point(colour = "red", size = 2) +  ylim(c(0,14)) +
    labs(subtitle = "Intervalos de 95% \n para la mediana")
g_1 + g_2
```

Donde: 

- En rojo está nuestro estimador puntual de la mediana de cada
grupo (la mediana muestral), y
- Las segmentos muestran un intervalo de confianza del 95\% 
para nuestra estimación de la mediana: esto quiere decir que 
los valores poblacionales tienen probabilidad aproximada de 95\% de estar
dentro del intervalo.

Este análisis comunica correctamente que tenemos **incertidumbre** alta acerca de nuestras
estimaciones (especialmente grupos b y c), y que no tenemos mucha evidencia de que el 
grupo b tenga una mediana poblacional considerablemente más alta que a o c. **En muchos casos
es más útil presentar la información de esta manera que usando alguna prueba
de hipótesis.**

Primero discutiremos cómo se interpretan y la idea básica que hay detrás de la construcción
de estos intervalos.

### Interpretación de intervalos de confianza {-}

Generalmente,  "intervalo de confianza" (de 90\% de confianza, por ejemplo) significa, desde
el punto de vista frecuentista:

- **Cada muestra produce un intervalo distinto**. Para el 90\% de las muestras posibles, el intervalo
cubre al valor poblacional.
- Así que con *alta probabilidad*, el valor poblacional está dentro del intervalo.
- Intervalos más anchos nos dan más incertidumbre acerca de dónde está el verdadero valor poblacional
(y al revés para intervalos más angostos)

Existen también "intervalos creíbles" (de 90\% de probabilidad, por ejemplo), que se interpetan de
forma bayesiana:

- Con 90\% de probabilidad (relativamente alta),creemos que el valor poblacional está dentro del intervalo creíble.

**Las técnicas que veremos a continuación se puede interpretar de las dos maneras**. 

- La interpretación bayesiana puede ser más natural
- La interpretación frecuentista nos da maneras empíricas de probar si los intervalos de
confianza están bien calibrados o no: es un mínimo que "intervalos del 90\%" debería satisfacer.

Así que tomamos el punto de vista bayesiano en la intepretación, pero 
buscamos que nuestros intervalos cumplan o 
aproximen bien garantías frecuentistas (discutimos esto más adelante).

### Cómo producir intervalos para estimación {-}

Existen muchas técnicas para construir estos intervalos que muestran la incertidumbre
en nuestras estimaciones: métodos basados en distribuciones estándar, métodos paramétricos
y no paramétricos, distintos métodos bayesianos (entonces se llaman intervalos
creíbles o de probabilidad), etc.

En este curso, como ejemplo, y también por ser una técnica versátil, presentaremos
el **bootstrap no paramétrico** (ver @bootefron), donde utilizaremos simulación (y poder de cómputo) para producir
este tipo de intervalos, bajo ciertas condiciones de extracción de la muestra que discutiremos
más adelante.


## La idea del bootstrap {-}


Como explicamos, el problema que tenemos ahora es que normalmente sólo tenemos una muestra, así que
no es posible calcular las distribuciones de muestreo como hicimos arriba. Sin embargo,
podemos hacer lo siguiente:

Supongamos que tenemos una muestra $X_1,X_2,\dots, X_n$ independientes de alguna
población desconocida y un estimador $T=t(X_1,\dots, X_n)$

1. Si tuviéramos la distribución poblacional, simulamos muestras iid para aproximar
la distribución de muestreo de nuestro estimador, y así entender su variabilidad.
2. Pero **no** tenemos la distribución poblacional
3. **Sin embargo, podemos estimar la distribución poblacional con nuestros valores muestrales**

**Mundo bootstrap**

4. Si usamos la estimación del inciso anterior, entonces usando 1 podríamos tomar muestras
de nuestros datos muestrales, como si fueran de la población, y usando el mismo tamaño de muestra. El muestreo lo hacemos con reemplazo de manera que produzcamos muestras independientes de la misma "población estimada", que es la muestra.
5. A la distribución resultante le llamamos **distribución bootstrap** de la muestra
6. Usamos la distribución bootstrap de la muestra para estimar la variabilidad en nuestra
estimación con **la muestra original**.


Veamos que sucede para un ejemplo concreto. Primero extraemos nuestra muestra:

```{r}
set.seed(2112)
muestra <- sample_n(casas_pob, 150, replace = T)
```

Esta muestra nos da nuestro estimador de la distribución poblacional:

```{r,  fig.width =5, fig.height = 3}
bind_rows(muestra %>% mutate(tipo = "muestra"),
    casas_pob %>% mutate(tipo = "población")) %>% 
ggplot(aes(sample = precio_miles, colour = tipo, group = tipo)) + 
    geom_qq(distribution = stats::qunif, alpha = 0.4, size = 1) + 
    scale_color_colorblind()
```

O con histogramas:

```{r,  fig.width =5, fig.height = 3}
bind_rows(muestra %>% mutate(tipo = "muestra"),
    casas_pob %>% mutate(tipo = "población")) %>% 
ggplot(aes(x = precio_miles, group = tipo)) + 
    geom_histogram(aes(y=..density..), binwidth = 50) + 
    scale_color_colorblind() +
    facet_wrap(~ tipo)
```

Y vemos que la aproximación es razonable, especialmente en las partes centrales de la 
distribución. Usamos nuestra muestra para estimar
la población.

Para evaluar ahora la variabilidad de nuestro estimador, podemos extraer un número
grande de muestras con reemplazo de tamaño 150 **de la muestra** - estamos en el mundo
Bootstrap! 

```{r}
mediana_muestras <- map_dbl(1:5000, ~ muestra %>%  
    sample_n(150, replace = T) %>%
    summarise(mediana_precio = median(precio_miles)) %>% pull(mediana_precio)) 
```

Y nuestra estimación de la distribución de muestreo para la mediana es entonces:

```{r, fig.width =4, fig.height = 3}
bootstrap <- tibble(mediana = mediana_muestras)
ggplot(bootstrap, aes(sample = mediana)) + geom_qq(distribution = stats::qunif)
```

Y podemos calcular ahora un intervalo de confianza del 90\% simplemente calculando los cuantiles de
esta distribución (no son los cuantiles de la muestra original!):

```{r}
limites_ic <- quantile(mediana_muestras, c(0.05,  0.95)) %>% round
limites_ic
```

Presentaríamos nuestro resultado como sigue: nuestra estimación puntual de la mediana es
`r median(muestra$precio_miles)`, con un intervalo de confianza del 90\% de (`r limites_ic[1]`, `r limites_ic[2]`)

```{block2, type='comentario'}
Los **intervalos de confianza bootstrap de percentiles** se calculan remuestreando la muestra
original, calculando la estadística de interés para cada remuestra, y finalmente,
calculando cuantiles de estos valores para obtener límite inferior y superior.
```
